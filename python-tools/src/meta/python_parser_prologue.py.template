"""
Auto-generated LL(k) recursive-descent parser.

Generated from protobuf specifications.
Do not modify this file! If you need to modify the parser, edit the generator code
in `python-tools/src/meta` or edit the protobuf specification in `proto/v1`.

{command_line_comment}"""

import hashlib
import re
from typing import List, Optional, Any, Tuple, Callable
from decimal import Decimal

from lqp.proto.v1 import logic_pb2, fragments_pb2, transactions_pb2


class ParseError(Exception):
    """Parse error exception."""
    pass


class Token:
    """Token representation."""
    def __init__(self, type: str, value: str, pos: int):
        self.type = type
        self.value = value
        self.pos = pos

    def __repr__(self) -> str:
        return f"Token({{self.type}}, {{self.value!r}}, {{self.pos}})"


class Lexer:
    """Tokenizer for the input."""
    def __init__(self, input_str: str):
        self.input = input_str
        self.pos = 0
        self.tokens: List[Token] = []
        self._tokenize()

    def _tokenize(self) -> None:
        """Tokenize the input string."""
        token_specs = [
{token_specs}        ]

        whitespace_re = re.compile(r'\s+')
        comment_re = re.compile(r';;.*')

        while self.pos < len(self.input):
            match = whitespace_re.match(self.input, self.pos)
            if match:
                self.pos = match.end()
                continue

            match = comment_re.match(self.input, self.pos)
            if match:
                self.pos = match.end()
                continue

            # Collect all matching tokens
            candidates = []

            for token_type, regex, action in token_specs:
                match = regex.match(self.input, self.pos)
                if match:
                    value = match.group(0)
                    candidates.append((token_type, value, action, match.end()))

            if not candidates:
                raise ParseError(f'Unexpected character at position {{{{self.pos}}}}: {{{{self.input[self.pos]!r}}}}')

            # Pick the longest match
            token_type, value, action, end_pos = max(candidates, key=lambda x: x[3])
            self.tokens.append(Token(token_type, action(value), self.pos))
            self.pos = end_pos

        self.tokens.append(Token('$', '', self.pos))

    @staticmethod
    def scan_symbol(s: str) -> str:
        """Parse SYMBOL token."""
        return s

    @staticmethod
    def scan_colon_symbol(s: str) -> str:
        """Parse COLON_SYMBOL token."""
        return s[1:]

    @staticmethod
    def scan_string(s: str) -> str:
        """Parse STRING token."""
        return s[1:-1].encode().decode('unicode_escape')  # Strip quotes and process escaping

    @staticmethod
    def scan_int(n: str) -> int:
        """Parse INT token."""
        return int(n)

    @staticmethod
    def scan_float(f: str) -> float:
        """Parse FLOAT token."""
        if f == 'inf':
            return float('inf')
        elif f == 'nan':
            return float('nan')
        return float(f)

    @staticmethod
    def scan_uint128(u: str) -> Any:
        """Parse UINT128 token."""
        uint128_val = int(u, 16)
        low = uint128_val & 0xFFFFFFFFFFFFFFFF
        high = (uint128_val >> 64) & 0xFFFFFFFFFFFFFFFF
        return logic_pb2.UInt128Value(low=low, high=high)

    @staticmethod
    def scan_int128(u: str) -> Any:
        """Parse INT128 token."""
        u = u[:-4]  # Remove the 'i128' suffix
        int128_val = int(u)
        low = int128_val & 0xFFFFFFFFFFFFFFFF
        high = (int128_val >> 64) & 0xFFFFFFFFFFFFFFFF
        return logic_pb2.Int128Value(low=low, high=high)

    @staticmethod
    def scan_decimal(d: str) -> Any:
        """Parse DECIMAL token."""
        # Decimal is a string like '123.456d12' where the last part after `d` is the
        # precision, and the scale is the number of digits between the decimal point and `d`
        parts = d.split('d')
        if len(parts) != 2:
            raise ValueError(f'Invalid decimal format: {{{{d}}}}')
        scale = len(parts[0].split('.')[1])
        precision = int(parts[1])
        # Parse the integer value directly without calling scan_int128 which strips 'i128' suffix
        int_str = parts[0].replace('.', '')
        int128_val = int(int_str)
        low = int128_val & 0xFFFFFFFFFFFFFFFF
        high = (int128_val >> 64) & 0xFFFFFFFFFFFFFFFF
        value = logic_pb2.Int128Value(low=low, high=high)
        return logic_pb2.DecimalValue(precision=precision, scale=scale, value=value)


class Parser:
    """LL(k) recursive-descent parser with backtracking."""
    def __init__(self, tokens: List[Token]):
        self.tokens = tokens
        self.pos = 0
        self.id_to_debuginfo = {{}}
        self._current_fragment_id: bytes | None = None
        self._relation_id_to_name = {{}}

    def lookahead(self, k: int = 0) -> Token:
        """Get lookahead token at offset k."""
        idx = self.pos + k
        return self.tokens[idx] if idx < len(self.tokens) else Token('$', '', -1)

    def consume_literal(self, expected: str) -> None:
        """Consume a literal token."""
        if not self.match_lookahead_literal(expected, 0):
            token = self.lookahead(0)
            raise ParseError(f'Expected literal {{expected!r}} but got {{token.type}}=`{{token.value!r}}` at position {{token.pos}}')
        self.pos += 1

    def consume_terminal(self, expected: str) -> Any:
        """Consume a terminal token and return parsed value."""
        if not self.match_lookahead_terminal(expected, 0):
            token = self.lookahead(0)
            raise ParseError(f'Expected terminal {{expected}} but got {{token.type}}=`{{token.value!r}}` at position {{token.pos}}')
        token = self.lookahead(0)
        self.pos += 1
        return token.value

    def match_lookahead_literal(self, literal: str, k: int) -> bool:
        """Check if lookahead token at position k matches literal.

        Supports soft keywords: alphanumeric literals are lexed as SYMBOL tokens,
        so we check both LITERAL and SYMBOL token types.
        """
        token = self.lookahead(k)
        if token.type == 'LITERAL' and token.value == literal:
            return True
        if token.type == 'SYMBOL' and token.value == literal:
            return True
        return False

    def match_lookahead_terminal(self, terminal: str, k: int) -> bool:
        """Check if lookahead token at position k matches terminal."""
        token = self.lookahead(k)
        return token.type == terminal

    def start_fragment(self, fragment_id: fragments_pb2.FragmentId) -> fragments_pb2.FragmentId:
        """Set current fragment ID for debug info tracking."""
        self._current_fragment_id = fragment_id.id
        return fragment_id

    def relation_id_from_string(self, name: str) -> Any:
        """Create RelationId from string and track mapping for debug info."""
        val = int(hashlib.sha256(name.encode()).hexdigest()[:16], 16)
        id_low = val & 0xFFFFFFFFFFFFFFFF
        id_high = (val >> 64) & 0xFFFFFFFFFFFFFFFF
        relation_id = logic_pb2.RelationId(id_low=id_low, id_high=id_high)

        # Store the mapping for the current fragment if we're inside one
        if self._current_fragment_id is not None:
            if self._current_fragment_id not in self.id_to_debuginfo:
                self.id_to_debuginfo[self._current_fragment_id] = {{}}
            self.id_to_debuginfo[self._current_fragment_id][(relation_id.id_low, relation_id.id_high)] = name

        return relation_id

    @staticmethod
    def _extract_value(val: Any, value_type: str, default: Any) -> Any:
        """Extract typed value from a protobuf Value wrapper."""
        if val is None:
            return default
        if value_type == 'int':
            return val.int_value if val.HasField('int_value') else default
        elif value_type == 'float':
            return val.float_value if val.HasField('float_value') else default
        elif value_type == 'str':
            return val.string_value if val.HasField('string_value') else default
        elif value_type == 'bool':
            return val.boolean_value if val.HasField('boolean_value') else default
        elif value_type == 'uint128':
            if hasattr(val, 'uint128_value') and val.HasField('uint128_value'):
                return val.uint128_value
            return val if val is not None else default
        elif value_type == 'bytes':
            if hasattr(val, 'string_value') and val.HasField('string_value'):
                return val.string_value.encode()
            return val if val is not None else default
        elif value_type == 'str_list':
            if val.HasField('string_value'):
                return [val.string_value]
            return default
        return default

    @staticmethod
    def _construct_from_schema(config_list: List[Tuple[str, Any]], schema: List[Tuple[str, str, str, Any]], message_class: type) -> Any:
        """Construct a protobuf message from config using a schema.

        Args:
            config_list: List of (key, value) tuples from parsing
            schema: List of (config_key, proto_field, value_type, default) tuples
            message_class: The protobuf message class to construct

        Returns:
            An instance of message_class with fields populated from config
        """
        config = {{k: v for k, v in config_list}}
        kwargs = {{}}
        for config_key, proto_field, value_type, default in schema:
            val = config.get(config_key)
            kwargs[proto_field] = Parser._extract_value(val, value_type, default)
        return message_class(**kwargs)

    def construct_configure(self, config_dict: List[Tuple[str, logic_pb2.Value]]) -> Any:
        """Construct Configure from config dictionary."""
        config = {{k: v for k, v in config_dict}}

        # Special handling for maintenance level enum
        maintenance_level = 'MAINTENANCE_LEVEL_OFF'
        maintenance_level_val = config.get('ivm.maintenance_level')
        if maintenance_level_val and maintenance_level_val.HasField('string_value'):
            level_str = maintenance_level_val.string_value.upper()
            if level_str in ('OFF', 'AUTO', 'ALL'):
                maintenance_level = f'MAINTENANCE_LEVEL_{{level_str}}'
            else:
                maintenance_level = level_str

        ivm_config = transactions_pb2.IVMConfig(level=maintenance_level)
        semantics_version = self._extract_value(config.get('semantics_version'), 'int', 0)
        return transactions_pb2.Configure(semantics_version=semantics_version, ivm_config=ivm_config)

    def export_csv_config(self, path: str, columns: List[Any], config_dict: List[Tuple[str, logic_pb2.Value]]) -> Any:
        """Construct ExportCsvConfig from path, columns, and config dictionary."""
        schema = [
            ('partition_size', 'partition_size', 'int', 0),
            ('compression', 'compression', 'str', ''),
            ('syntax_header_row', 'syntax_header_row', 'bool', True),
            ('syntax_missing_string', 'syntax_missing_string', 'str', ''),
            ('syntax_delim', 'syntax_delim', 'str', ','),
            ('syntax_quotechar', 'syntax_quotechar', 'str', '"'),
            ('syntax_escapechar', 'syntax_escapechar', 'str', '\\'),
        ]
        msg = self._construct_from_schema(config_dict, schema, transactions_pb2.ExportCSVConfig)
        msg.path = path
        msg.data_columns.extend(columns)
        return msg

    def construct_betree_info(self, key_types: List[Any], value_types: List[Any], config_dict: List[Tuple[str, Any]]) -> Any:
        """Construct BeTreeInfo from key_types, value_types, and config dictionary."""
        config_schema = [
            ('betree_config_epsilon', 'epsilon', 'float', 0.5),
            ('betree_config_max_pivots', 'max_pivots', 'int', 4),
            ('betree_config_max_deltas', 'max_deltas', 'int', 16),
            ('betree_config_max_leaf', 'max_leaf', 'int', 16),
        ]
        storage_config = self._construct_from_schema(config_dict, config_schema, logic_pb2.BeTreeConfig)

        locator_schema = [
            ('betree_locator_root_pageid', 'root_pageid', 'uint128', None),
            ('betree_locator_inline_data', 'inline_data', 'bytes', None),
            ('betree_locator_element_count', 'element_count', 'int', 0),
            ('betree_locator_tree_height', 'tree_height', 'int', 0),
        ]
        relation_locator = self._construct_from_schema(config_dict, locator_schema, logic_pb2.BeTreeLocator)

        return logic_pb2.BeTreeInfo(
            key_types=key_types,
            value_types=value_types,
            storage_config=storage_config,
            relation_locator=relation_locator
        )

    def construct_csv_config(self, config_dict: List[Tuple[str, Any]]) -> Any:
        """Construct CSVConfig from config dictionary."""
        schema = [
            ('csv_header_row', 'header_row', 'int', 1),
            ('csv_skip', 'skip', 'int', 0),
            ('csv_new_line', 'new_line', 'str', ''),
            ('csv_delimiter', 'delimiter', 'str', ','),
            ('csv_quotechar', 'quotechar', 'str', '"'),
            ('csv_escapechar', 'escapechar', 'str', '"'),
            ('csv_comment', 'comment', 'str', ''),
            ('csv_missing_strings', 'missing_strings', 'str_list', []),
            ('csv_decimal_separator', 'decimal_separator', 'str', '.'),
            ('csv_encoding', 'encoding', 'str', 'utf-8'),
            ('csv_compression', 'compression', 'str', 'auto'),
        ]
        return self._construct_from_schema(config_dict, schema, logic_pb2.CSVConfig)

    def construct_fragment(self, fragment_id: fragments_pb2.FragmentId, declarations: List[logic_pb2.Declaration]) -> fragments_pb2.Fragment:
        """Construct Fragment from fragment_id, declarations, and debug info from parser state."""
        # Get the debug info for this fragment
        debug_info_dict = self.id_to_debuginfo.get(fragment_id.id, {{}})

        # Convert to DebugInfo protobuf
        ids = []
        orig_names = []
        for (id_low, id_high), name in debug_info_dict.items():
            ids.append(logic_pb2.RelationId(id_low=id_low, id_high=id_high))
            orig_names.append(name)

        # Create DebugInfo
        debug_info = fragments_pb2.DebugInfo(ids=ids, orig_names=orig_names)

        # Clear _current_fragment_id before the return
        self._current_fragment_id = None

        # Create and return Fragment
        return fragments_pb2.Fragment(id=fragment_id, declarations=declarations, debug_info=debug_info)
{parse_nonterminal_defns}

def parse(input_str: str) -> Any:
    """Parse input string and return parse tree."""
    lexer = Lexer(input_str)
    parser = Parser(lexer.tokens)
    result = parser.parse_{start_name}()
    # Check for unconsumed tokens (except EOF)
    if parser.pos < len(parser.tokens):
        remaining_token = parser.lookahead(0)
        if remaining_token.type != '$':
            raise ParseError(f"Unexpected token at end of input: {{remaining_token}}")
    return result
